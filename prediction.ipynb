{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIT5149 - Applied Data Analysis: Assignment 1 (Monthly Stock Prediction: Prediction)\n",
    "\n",
    "This notebook covers the final prediction part of the assignment using the trained ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"data\"):\n",
    "    # Primary data\n",
    "    primary_data_dir = Path(data_dir)\n",
    "    stock = pd.read_csv(primary_data_dir/\"stock_data.csv\")\n",
    "    company = pd.read_csv(primary_data_dir/\"company_info.csv\")\n",
    "    index = pd.read_csv(primary_data_dir/\"monashIndex.csv\")\n",
    "    train_targets = pd.read_csv(primary_data_dir/\"training_targets.csv\")\n",
    "\n",
    "    # Optional data\n",
    "    optional_data_dir = primary_data_dir/\"optional_data\"\n",
    "    optional_data_list = []\n",
    "    for fname in optional_data_dir.glob(\"*.csv\"):\n",
    "        optional_data_list.append(pd.read_csv(fname))\n",
    "    \n",
    "    return stock, company, index, train_targets, optional_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock, company, index, train_targets, optional_data_list = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(stock, company, index, train_targets, optional_data_list=None):\n",
    "    # Add the test data to predict for month_id \"2023_07\"\n",
    "    next_month_df = pd.DataFrame({\"month_id\": [\"2023_07\"]*len(company), \"stock_id\": company[\"stock_id\"].values})\n",
    "    new_stock = pd.concat([stock, next_month_df])\n",
    "    \n",
    "    # Merge/join the primary data\n",
    "    df = pd.merge(new_stock, company, on=[\"stock_id\"], how=\"left\")\n",
    "    df = pd.merge(df, index, on=[\"month_id\"], how=\"left\")\n",
    "    df = pd.merge(df, train_targets, on=[\"month_id\", \"stock_id\"], how=\"left\")\n",
    "\n",
    "    # Optionally merge the optional data\n",
    "    if optional_data_list:\n",
    "        for optional_data in optional_data_list:\n",
    "            df = pd.merge(df, optional_data, on=[\"month_id\"], how=\"left\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not use any optional features (see our modelling experiment notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merge_data(stock, company, index, train_targets, optional_data_list=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imput missing columns and build rolling/window features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_columns(df, imputation_method):    \n",
    "    for column in df.columns:\n",
    "        if column in [\"month_id\", \"stock_id\"]:  # never impute ID columns\n",
    "            continue\n",
    "        \n",
    "        if imputation_method == \"ffill\":\n",
    "            df[column] = df[column].fillna(method=\"ffill\")\n",
    "        elif imputation_method == \"median\":\n",
    "            df[column] = df[column].fillna(df[column].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def compute_rolling_statistic_features(df, macro_cols):\n",
    "    grouped = df.groupby('stock_id')\n",
    "\n",
    "    # Price-based returns \n",
    "    for window in [3, 6, 12]:\n",
    "        df[f'intramonth_return_rolling_mean_{window}m']   = grouped['intramonth_return'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'intramonth_return_rolling_std_{window}m']    = grouped['intramonth_return'].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "        df[f'intramonth_return_rolling_median_{window}m'] = grouped['intramonth_return'].transform(lambda x: x.rolling(window, min_periods=1).median())\n",
    "\n",
    "    # Lagged returns \n",
    "    for col in ['return_1m', 'return_3m', 'return_6m']:\n",
    "        for lag in [1, 2]:\n",
    "            df[f'{col}_lagged_{lag}'] = grouped[col].shift(lag)\n",
    "\n",
    "    # Volatility features\n",
    "    for col, windows in [\n",
    "        ('intramonth_volatility', [3, 6, 12]),\n",
    "        ('volatility_3m', [3, 6]),\n",
    "        ('volatility_6m', [3, 6])\n",
    "    ]:\n",
    "        for window in windows:\n",
    "            df[f'{col}_rolling_mean_{window}m'] = grouped[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            df[f'{col}_rolling_std_{window}m']  = grouped[col].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "\n",
    "    # Volume features\n",
    "    for col, windows in [\n",
    "        ('monthly_volume', [3, 6]),\n",
    "        ('avg_volume_3m', [3, 6]),\n",
    "        ('volume_ratio', [3, 6])\n",
    "    ]:\n",
    "        for window in windows:\n",
    "            df[f'{col}_rolling_mean_{window}m'] = grouped[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "            df[f'{col}_rolling_sum_{window}m']  = grouped[col].transform(lambda x: x.rolling(window, min_periods=1).sum())\n",
    "\n",
    "    # Price range\n",
    "    df['price_range'] = df['month_high_usd'] - df['month_low_usd']\n",
    "    for window in [3, 6, 12]:\n",
    "        df[f'price_range_rolling_mean_{window}m']       = grouped['price_range'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'price_range_ratio_rolling_mean_{window}m'] = grouped['price_range_ratio'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "\n",
    "    # Index rolling features\n",
    "    for window in [3, 6]:\n",
    "        df[f'index_return_rolling_mean_{window}m'] = grouped['index_return'].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "        df[f'index_return_rolling_std_{window}m']  = grouped['index_return'].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "\n",
    "    # Additional features\n",
    "    if macro_cols:\n",
    "        for col in macro_cols:\n",
    "            for window in [3, 6, 12]:\n",
    "                df[f'{col}_rolling_mean_{window}m'] = df.groupby('month_id')[col].transform(lambda x: x.rolling(window, min_periods=1).mean())\n",
    "                df[f'{col}_rolling_std_{window}m']  = df.groupby('month_id')[col].transform(lambda x: x.rolling(window, min_periods=1).std())\n",
    "\n",
    "    return df\n",
    "    \n",
    "def handle_missing_rolling_features(df, strategy=\"drop\", fill_value=0):\n",
    "    rolling_cols = [c for c in df.columns if \"lag\" in c or \"rolling\" in c]\n",
    "    if strategy == \"drop\":\n",
    "        df = df.dropna(subset=rolling_cols)\n",
    "    elif strategy == \"fill\":\n",
    "        df[rolling_cols] = df[rolling_cols].fillna(fill_value)\n",
    "    elif strategy == \"ffill\":\n",
    "        df[rolling_cols] = df[rolling_cols].fillna(method=\"ffill\")\n",
    "    elif strategy == \"bfill\":\n",
    "        df[rolling_cols] = df[rolling_cols].fillna(method=\"bfill\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def build_training_data(df, imputation_method, macro_cols=None,\n",
    "                        build_additional_features=False, handle_missing_rolling_features_strategy=\"bfill\"):\n",
    "    train_df = df.copy()\n",
    "    train_df = impute_missing_columns(train_df, imputation_method=imputation_method)\n",
    "    train_df = train_df.sort_values(by=[\"stock_id\", \"month_id\"])\n",
    "    \n",
    "    if build_additional_features:\n",
    "        train_df = compute_rolling_statistic_features(train_df, macro_cols)\n",
    "        train_df = handle_missing_rolling_features(train_df, strategy=handle_missing_rolling_features_strategy)\n",
    "    \n",
    "    train_df[\"outperform_binary\"] = df[\"outperform_binary\"]\n",
    "    train_df[\"excess_return\"] = df[\"excess_return\"]\n",
    "    \n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archel\\AppData\\Local\\Temp\\ipykernel_9984\\3088241577.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[column] = df[column].fillna(method=\"ffill\")\n",
      "C:\\Users\\Archel\\AppData\\Local\\Temp\\ipykernel_9984\\3088241577.py:76: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[rolling_cols] = df[rolling_cols].fillna(method=\"bfill\")\n"
     ]
    }
   ],
   "source": [
    "train_df = build_training_data(df, imputation_method=\"ffill\",\n",
    "                               macro_cols=None, \n",
    "                               build_additional_features=True,\n",
    "                               handle_missing_rolling_features_strategy=\"bfill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split between training and test data. We will be using the test data only this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, task):\n",
    "    train_df = df[df['month_id'] <= \"2023_06\"]\n",
    "    test_df = df[df['month_id'] == \"2023_07\"]\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"outperform_binary\", \"excess_return\"], axis=1)\n",
    "    X_test = test_df.drop(columns=[\"outperform_binary\", \"excess_return\"], axis=1)\n",
    "    if task == \"classification\":\n",
    "        y_train = train_df['outperform_binary'].astype(int)\n",
    "    elif task == \"regression\":\n",
    "        y_train = train_df['excess_return'].astype(float)\n",
    "\n",
    "    return X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_clf, y_train_clf, X_test_clf = split_data(train_df, task=\"classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `TopKFeatureSelector` class as the top feature selector pipeline step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TopKFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_names, importances, k=20):\n",
    "        self.feature_names = feature_names\n",
    "        self.importances = importances\n",
    "        self.k = k\n",
    "        self.selected_idx = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        ranking = np.argsort(self.importances)[::-1]\n",
    "        self.selected_idx = ranking[:self.k]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.selected_idx]\n",
    "\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [self.feature_names[i] for i in self.selected_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict test data for `outperform_binary` and `excess_return` and save the prediction results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archel\\AppData\\Local\\Temp\\ipykernel_9984\\2853924202.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission_df[\"outperform_binary\"] = clasification_ensemble_pipeline.predict(X_test_clf)\n",
      "C:\\Users\\Archel\\AppData\\Local\\Temp\\ipykernel_9984\\2853924202.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission_df[\"excess_return\"] = regression_ensemble_pipeline.predict(X_test_clf)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_id</th>\n",
       "      <th>month_id</th>\n",
       "      <th>outperform_binary</th>\n",
       "      <th>excess_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25618</th>\n",
       "      <td>US001</td>\n",
       "      <td>2023_07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25619</th>\n",
       "      <td>US002</td>\n",
       "      <td>2023_07</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.002541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25620</th>\n",
       "      <td>US003</td>\n",
       "      <td>2023_07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25621</th>\n",
       "      <td>US004</td>\n",
       "      <td>2023_07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.015339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25622</th>\n",
       "      <td>US005</td>\n",
       "      <td>2023_07</td>\n",
       "      <td>1</td>\n",
       "      <td>0.012703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      stock_id month_id  outperform_binary  excess_return\n",
       "25618    US001  2023_07                  0       0.000332\n",
       "25619    US002  2023_07                  0      -0.002541\n",
       "25620    US003  2023_07                  0       0.011159\n",
       "25621    US004  2023_07                  1       0.015339\n",
       "25622    US005  2023_07                  1       0.012703"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"files/models/classification/final_voting_classifier.pkl\", 'rb') as file:\n",
    "    clasification_ensemble_pipeline = pickle.load(file)\n",
    "with open(\"files/models/regression/final_voting_classifier.pkl\", 'rb') as file:\n",
    "    regression_ensemble_pipeline = pickle.load(file)\n",
    "\n",
    "submission_df = X_test_clf[[\"stock_id\", \"month_id\"]]\n",
    "submission_df[\"outperform_binary\"] = clasification_ensemble_pipeline.predict(X_test_clf)\n",
    "submission_df[\"excess_return\"] = regression_ensemble_pipeline.predict(X_test_clf)\n",
    "submission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_submission_df = submission_df[[\"stock_id\", \"excess_return\"]]\n",
    "submission_df.to_csv(\"files/submission/testing_targets.csv\", index=False)\n",
    "kaggle_submission_df.to_csv(\"files/submission/kaggle_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fit5149",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
